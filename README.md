## Contents

- [GAN](#gan)
- [Prerequisites and Installation](#prerequisites-and-installation)
- [Training](#training)
- [Generation](#generation)

# GAN

A simple implementation of a Generative Adversarial Neural Network (GANs) for generating numbers using the MINST dataset.

The GANs are well-known neural network architecture for image generation. The basic idea behind GANS is to set 2 Artificial Neural Networks (ANN) to fight each other. The first one is the Discriminator, which has as its main goal to distinguish whether a certain image came from our dataset or is generated by the generator. The second model, the generator, as the name suggests, is responsible for generating the desired image based on a noisy image or the previous iteration image. Therefore, the role of the generator is to fool the discriminator by providing a very similar image. 

In this neural network architecture, the loss function plays an important role in guiding both models. The discriminator loss function will try to make its output to be nearly 1 for real image input and 0 for fake image input. On the other hand, as the generator has to deceive the discriminator, it will try to make the output more realistic, causing the minimization of part of the discriminator loss function that should be maximized by the discriminator. The details of both loss functions are depicted in the image below:

![gans](https://github.com/HerbertHipolito/generative-adversarial-neural-network/assets/94997683/b28e4147-7dc2-479c-b6b4-100867aeb37d)

In order to lead the generator model to create an image of a desired class, both the discriminator and generator receive an array (1,794) in which the last 10 elements represent the class and the rest is the image itself. Thereby, the user can choose a particular number in the image to be generated.

As my first implementation, I used an MLP architecture for the generator and discriminator models in a handwritten digit-based dataset (MINST). This dataset contains around 70 thousand of 28x28 grey images ranging from 0 to 9. The images are vectorized (1,784) to fit into the discriminator. The generator receives the concatenation between vectorized noisy image generated by a normal distribution and a (1,10) array that represents the class of the image which will be created. All elements of this array are the current class.

In regard to the discriminator and generator architecture, the generator is composed of 3 hidden layers with a Leaky ReLU activation function and 256, 512, and 1024 neurons in order. The output layer contains 784 neurons (vectorized image size) with a Hyperbolic tangent activation function. The discriminator has a similar structure with the reverse order of the number of hidden layer neurons and the Sigmoid activation function in the output layer.

![modelsGAns](https://github.com/HerbertHipolito/generative-adversarial-neural-network/assets/94997683/283fe337-6330-4f20-8861-e93b7af22a4e)

The results after using around 40 epochs, discriminator rate learning = 1e-5, generator rate learning = 4e-5, and 3 numbers set up (1, 4, 7) are displayed  below:

![collage](https://github.com/HerbertHipolito/generative-adversarial-neural-network/assets/94997683/28aad9c2-590d-4c61-9dd8-6f1b382555f9)

I just selected 3 numbers because it can take a considerable time to train a GAN model.
The GIF below shows the process of creating an image.

![gans](https://github.com/HerbertHipolito/generative-adversarial-neural-network/assets/94997683/52eac4bf-df49-484b-977a-6f1994a1ac22)

The GANs are really interesting ANN architecture. However, its training may be hard as GANs are unstable, leading easily to gradient vanishing. 

# Prerequisites and Installation

* keras==2.10.0
* matplotlib==3.7.0
* numpy==1.24.3
* Pillow==9.4.0
* pyTelegramBotAPI==4.12.0
* scikit_learn==1.2.2
* tensorflow==2.11.0
* tensorflow_intel==2.11.0
* tqdm==4.64.1

Clone this repository and run the following command to get started with this project:

pip install -r requirements.txt

# Training
```
python train.py [-h] [--epochs EPOCHS] [--tries TRIES] [--batch BATCH] [--num_processes NUM_PROCESSES] [--learning_rate_discriminator LEARNING_RATE_DISCRIMINATOR] [--learning_rate_generator LEARNING_RATE_GENERATOR]
                [--telegram_information TELEGRAM_INFORMATION]

options:
  -h, --help            show this help message and exit
  --epochs EPOCHS
  --tries TRIES         Early Stopping parameter. The number of attempts that the model will keep training with no improvement
  --sleep_discriminator SLEEP_DISCRIMINATOR
                        Number of loops that Discriminator will not update the weights
  --batch BATCH         Mini-batch size
  --selected_numbers SELECTED_NUMBERS [SELECTED_NUMBERS ...]
                        The numbers in the images to be generated. More numbers will make the training take more time
  --learning_rate_discriminator LEARNING_RATE_DISCRIMINATOR
  --learning_rate_generator LEARNING_RATE_GENERATOR
  --telegram_information TELEGRAM_INFORMATION
                        Send information via the Telegram bot about the training process, including an image at the end of each epoch. It's needed to set the key and chat_id: Just go to telegram_bot => variables and replace them

```
You can select which number images the model will train on by setting up the parameter 'selected_number'. 

If you wish to be notified via Telegram about the state of model training, you can use --telegram_information True and set your telegram_key and chat_id in the file telegram_bot/variables.py. afterward, at and of each epoch, you will receive information about the training process and a generated image.

# Generation

```
usage: generate.py [-h] [--mean MEAN] [--std STD] [--img_number IMG_NUMBER] [--show_img SHOW_IMG] [--show_discriminator_output SHOW_DISCRIMINATOR_OUTPUT]

options:
  -h, --help            show this help message and exit
  --mean MEAN           The noisy img will be generated following a normal distribution with the set mean.
  --std STD             The noisy img will be generated following a normal distribution with the set standard deviation.
  --img_number IMG_NUMBER
                        The number of images to be generated by the algorithm.
  --show_img SHOW_IMG   show the imgs after the generation process
  --gif GIF             Create a gif with all generated images
  --show_discriminator_output SHOW_DISCRIMINATOR_OUTPUT
                        Show a graph line with the results of the discriminator model in the generated images
  --selected_numbers SELECTED_NUMBERS [SELECTED_NUMBERS ...]
                        The numbers in the images to be generated. More numbers will make the training take more time

```


